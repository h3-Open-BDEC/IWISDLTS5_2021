<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Workshop h3-Open-BDEC</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="Site for Workshop">
<meta name="keywords" content="Workshop,h3-Open-BDEC,">
<link rel="stylesheet" href="css/style.css">
<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>

<body>

<div id="container">

<header>
<!-- <h1 id="logo"><a href="index.html"><img src="images/logo.png" alt="SAMPLE SITE"></a></h1> -->
<aside id="mainimg"><img src="images/bunner_trim.jpg" alt=""></aside>
</header>

<nav id="menubar">
<ul>
<li><a href="index.html">Top</a></li>
<li><a href="goal.html">Goal</a></li>
<li><a href="program.html">Program</a></li>
<li><a href="https://u-tokyo-ac-jp.zoom.us/meeting/register/tZcscOuhrDstHtDug9CINxqY3ZGeGfz5szh4">Registration</a></li>
<li><a href="link.html">Link</a></li>
</ul>
</nav>

<div id="contents">

<section>

<h2>Program</h2>
<font size=+1> To see the abstract, hold the mouse cursor over the title or click it.</font><br>
<table class="ta1">
<caption>Session 1 (<a title="
30 Nov 07:00&sim;08:50 CTT
30 Nov 00:00&sim;01:50 CET
29 Nov 18:00&sim;19:50 EST
29 Nov 15:00&sim;16:50 PST"><u>30 Nov 08:00~09:50 JST</u></a>)<br>
  Adaptive precision, AT & Verification (I)</caption>
<tr>
<th>08:00~08:30</th>
<td><b>Kengo Nakajima</b> (The University of Tokyo) : <b>Overview</b></td>
</tr>
<tr>
<th>08:30~08:50<br>
</a>
</th>
<td><b>Takeshi Iwashita</b>, Takeshi Fukaya (Hokkaido University)<br>
<a href="Abstract/TakeshiIwashita.html" title="In this talk, we introduce the convergence equivalence condition for parallel orderings in the context of IC(0) preconditioning. Based on the condition, we propose a new parallel ordering method to vectorize and parallelize IC(0) preconditioning, which is called hierarchical block multi-color (HBMC) ordering. The parallel forward and backward substitutions can be vectorized while preserving the advantages of block multi-color ordering, that is, fast convergence and fewer thread synchronizations. Numerical tests were conducted using seven test matrices from the SuiteSparse matrix collection on three types of computational nodes (Intel Xeon Skylake, Broadwell, and Xeon Phi processors). The numerical results indicate that HBMC ordering outperforms the conventional block and nodal multi-color ordering methods. HBMC ordering attains the best result among three parallel ordering methods in 18 out of 21 test cases. 
In this talk, we introduce the convergence equivalence condition for parallel orderings in the context of IC(0) preconditioning. Based on the condition, we propose a new parallel ordering method to vectorize and parallelize IC(0) preconditioning, which is called hierarchical block multi-color (HBMC) ordering. The parallel forward and backward substitutions can be vectorized while preserving the advantages of block multi-color ordering, that is, fast convergence and fewer thread synchronizations. Numerical tests were conducted using seven test matrices from the SuiteSparse matrix collection on three types of computational nodes (Intel Xeon Skylake, Broadwell, and Xeon Phi processors). The numerical results indicate that HBMC ordering outperforms the conventional block and nodal multi-color ordering methods. HBMC ordering attains the best result among three parallel ordering methods in 18 out of 21 test cases. 
"><b>HBMC Ordering for SIMD Vectorization of IC Preconditioning</b></a>
</td>
</tr>
<tr>
<th>08:50~09:10</th>
<td><b>Masatoshi Kawai</b> (The University of Tokyo)<br>
 <a href="Abstract/MasatoshiKawai.html" title="Integration of simulation, data analytics, and machine learning requires communication between different types of parallel computers, such as ones with a massive number of nodes and ones with accelerators. Parallel computers of different types are usually installed as independent systems. MPI handles communication in each system, but it cannot do for communication across the systems. WaitIO is a new communication library that provides a communication infrastructure for applications that utilize multiple parallel computers. While providing similar APIs with MPI, it provides communication functionalities between parallel computers where TCP/IP or shared file systems are only the way of communication. This talk introduces the basic design of WaitIO and reports its performance and scalabilities."><b>Low/Adaptive Precision Computation in Preconditioned Iterative Solvers for Ill-Conditioned Problems</b></a>
</td>
</tr>
<tr>
  <th>09:10~09:50</th>
  <td><font color="red"><b>INVITED TALK</b></font><br>
 <b>Rich Vuduc</b> (Georgia Institute of Technology, USA)<br>
 <a href="Abstract/RichVuduc.html" title="We consider the emergence of so-called “smart” network interface cards, or smartNICs, for high-performance computing systems, focusing on the class of such platforms where the on-NIC “smarts” are supplied by general-purpose multicore processors (in contrast to ASICs or FPGAs). This class has been rebranded by at least one vendor as that of data processing units, or DPUs. Given DPUs, how should one redesign HPC algorithms and software to exploit them? This talk describes our ongoing work to try to answer this question, using mini-applications from computational science and engineering, including molecular dynamics, adaptive mesh refinement, and communication-avoiding (time-tiled) stencil computations as case studies. This work is led by Sara Karamati, a Ph.D. student at Georgia Tech, and joint with Jeffrey Young (also GT) and colleagues at Sandia National Laboratories."><b>Smarter Algorithms for Smarter Networks?</b></a>

</td>
</tr>
</table>


<table class="ta1">
  <caption>Session 2 (<a title="
30 Nov 15:00&sim;17:30 CTT
30 Nov 08:00&sim;10:30 CET
30 Nov 02:00&sim;04:30 EST
29 Nov 23:00&sim;25:30 PST"><u>30 Nov 16:00~18:30 JST</u></a>)<br>
  Integration of (S+D+L) (I)</caption>
<tr>
  <th>16:00~16:40</th>
  <td><font color="red"><b>INVITED TALK</b></font><br>
  <b>Kento Sato</b> (RIKEN R-CCS, Japan)<br>
 <a href="Abstract/KentoSato.html" title="Integration of simulation, data analytics, and machine learning requires communication between different types of parallel computers, such as ones with a massive number of nodes and ones with accelerators. Parallel computers of different types are usually installed as independent systems. MPI handles communication in each system, but it cannot do for communication across the systems. WaitIO is a new communication library that provides a communication infrastructure for applications that utilize multiple parallel computers. While providing similar APIs with MPI, it provides communication functionalities between parallel computers where TCP/IP or shared file systems are only the way of communication. This talk introduces the basic design of WaitIO and reports its performance and scalabilities."><b>High Performance Big Data Systems for Extreme-scale Data Science on Fugaku</b></a>
</td>
</tr>
<tr>
<th>16:40~17:00</th>
<td><b>Takashi Shimokawabe</b> (The University of Tokyo)<br>
 <a href="Abstract/TakashiShimokawabe.html" title="Integration of simulation, data analytics, and machine learning requires communication between different types of parallel computers, such as ones with a massive number of nodes and ones with accelerators. Parallel computers of different types are usually installed as independent systems. MPI handles communication in each system, but it cannot do for communication across the systems. WaitIO is a new communication library that provides a communication infrastructure for applications that utilize multiple parallel computers. While providing similar APIs with MPI, it provides communication functionalities between parallel computers where TCP/IP or shared file systems are only the way of communication. This talk introduces the basic design of WaitIO and reports its performance and scalabilities."><b>Fast Prediction Method for Approximating Steady Flow Simulations over Multiple Domains</b></a>
</td>
</tr>
<tr>
<th>17:00~17:20</th>  
<td><b>Hayato Shiba</b> (The University of Tokyo)</b><br>
 <a href="Abstract/HayatoShiba.html" title="Integration of simulation, data analytics, and machine learning requires communication between different types of parallel computers, such as ones with a massive number of nodes and ones with accelerators. Parallel computers of different types are usually installed as independent systems. MPI handles communication in each system, but it cannot do for communication across the systems. WaitIO is a new communication library that provides a communication infrastructure for applications that utilize multiple parallel computers. While providing similar APIs with MPI, it provides communication functionalities between parallel computers where TCP/IP or shared file systems are only the way of communication. This talk introduces the basic design of WaitIO and reports its performance and scalabilities."><b>Enhancement of Molecular Dynamics Simulation by Machine Learning</b></a>
</td>
</tr>
<tr>
<th>17:20~18:00</th>
<td>
  <font color="red"><b>INVITED TALK</b></font><br>
  <b>Weichung Wang</b> (National Taiwan University, Taiwan) <br>
 <a href="Abstract/WeichungWang.html" title="The rapid development of Artificial Intelligence (AI) introduces a promising new era of smart and precision medicine. Interdisciplinary collaborations play a critical role in the research, education, and productization of medical AI. We will illustrate how the "Medical Data Analytics Framework" may achieve the end-to-end R&D life-cycle. The framework includes project design, multimodality data, intelligent analytics, medical workflows, regulation and ethics, and solution landing. We will also demonstrate examples of how medical AI algorithms and tools can reduce physicians' loading and improve patient outcomes."><b>Medical Data Analytics and Beyond</b></a>
</td>
</tr>
</table>


<table class="ta1">
  <caption>Session 3 (<a title="
30 Nov 07:00&sim;09:20 CTT
30 Nov 00:00&sim;02:20 CET
29 Nov 18:00&sim;20:20 EST
29 Nov 15:00&sim;17:20 PST"><u>3 Dec 8:00~10:20 JST</u></a>)<br>
  Adaptive precision, AT & Verification (II)</caption>
<tr>
<th>08:00~08:40</th>
<td>
  <font color="red"><b>INVITED TALK</b></font><br>
  <b>Osni Marques</b>, Doru Thom Popovici, Mauro Del Ben and Andrew Canning (Lawrence Berkeley National Laboratory, USA)<br>
 <a href="Abstract/OsniMarques.html" title="Integration of simulation, data analytics, and machine learning requires communication between different types of parallel computers, such as ones with a massive number of nodes and ones with accelerators. Parallel computers of different types are usually installed as independent systems. MPI handles communication in each system, but it cannot do for communication across the systems. WaitIO is a new communication library that provides a communication infrastructure for applications that utilize multiple parallel computers. While providing similar APIs with MPI, it provides communication functionalities between parallel computers where TCP/IP or shared file systems are only the way of communication. This talk introduces the basic design of WaitIO and reports its performance and scalabilities."><b>Revisiting Minimization Strategies for Solving Eigenvalue Problems</b></a>
</tr>
<tr>
<th>08:40~09:00</th>
<td><b>Takahiro Katagiri</b> (Nagoya University)<br>
 <a href="Abstract/TakahiroKatagiri.html" title="Integration of simulation, data analytics, and machine learning requires communication between different types of parallel computers, such as ones with a massive number of nodes and ones with accelerators. Parallel computers of different types are usually installed as independent systems. MPI handles communication in each system, but it cannot do for communication across the systems. WaitIO is a new communication library that provides a communication infrastructure for applications that utilize multiple parallel computers. While providing similar APIs with MPI, it provides communication functionalities between parallel computers where TCP/IP or shared file systems are only the way of communication. This talk introduces the basic design of WaitIO and reports its performance and scalabilities."><b>Recent Challenges of Auto-tuning: Accuracy Optimization and Explainable AI</b></a>
</td>
</tr>
<tr>
<th>09:00~09:20</th>
<td><b>Takeshi Ogita</b> (Tokyo Woman’s Christian University)<br>
 <a href="Abstract/TakeshiOgita.html" title="Integration of simulation, data analytics, and machine learning requires communication between different types of parallel computers, such as ones with a massive number of nodes and ones with accelerators. Parallel computers of different types are usually installed as independent systems. MPI handles communication in each system, but it cannot do for communication across the systems. WaitIO is a new communication library that provides a communication infrastructure for applications that utilize multiple parallel computers. While providing similar APIs with MPI, it provides communication functionalities between parallel computers where TCP/IP or shared file systems are only the way of communication. This talk introduces the basic design of WaitIO and reports its performance and scalabilities."><b>Accurately Verified Numerical Solutions of Large Sparse Linear Systems Arising from 3D Poisson Equation</b></a>
</td>
</tr>
<tr>
<th>09:20~09:40</th>
<td>
 <font color="red"><b>INVITED TALK</b></font><br>
 <b>Takeshi Fukaya</b> (Hokkaido Univsersity, JST PRESTO, Japan)<br>
 <a href="Abstract/TakeshiFukaya.html" title="Integration of simulation, data analytics, and machine learning requires communication between different types of parallel computers, such as ones with a massive number of nodes and ones with accelerators. Parallel computers of different types are usually installed as independent systems. MPI handles communication in each system, but it cannot do for communication across the systems. WaitIO is a new communication library that provides a communication infrastructure for applications that utilize multiple parallel computers. While providing similar APIs with MPI, it provides communication functionalities between parallel computers where TCP/IP or shared file systems are only the way of communication. This talk introduces the basic design of WaitIO and reports its performance and scalabilities."><b>Exploring the Potential of Low Precision Computing in the GMRES(m) Method</b></a>
</td>
</tr>
<tr>
<th>09:40~10:20</th>
<td><b>Discussions on Computing by Low/Adaptive Precesion</b>
</td>
</tr>
</table>


<table class="ta1">
  <caption>Session 4 (<a title="
3 Nov 15:00&sim;17:10 CTT
3 Nov 08:00&sim;10:10 CET
3 Nov 02:00&sim;04:10 EST
2 Nov 23:00&sim;25:10 PST"><u>3 Dec 16:00~18:10 JST</u></a>)<br>
  Integration of (S+D+L) (II)</caption>
<tr>
<th>16:00~16:40</th>
<td>
  <font color="red"><b>INVITED TALK</b></font><br>
  <b>Gerhard Wellein</b> (Erlangen National High-Performance Computing Center (NHR@FAU) & Friedrich-Alexander-Universität Erlangen - Nürnberg, Germany)<br>
 <a href="Abstract/GerhardWellein.html" title="HPC infrastructures provide the backbone for advanced numerical simulation, large scale data analytics or machine learning applications. Rapid technology advances, heterogeneity in hardware or power constraints are only a few developments which require HPC hardware to be seamlessly embedded into an environment of extensive user support, training and expert knowledge in various disciplines. In response to these challenges, Germany has recently established the National High-Performance Computing (NHR) Alliance as a long-term nationwide infrastructure, combining operational, training and research expertise of eight universities. The talk first introduces the NHR Alliance and puts it into the context of the German HPC ecosystem. In the second part, recent results from NHR technology exploration activities for the A64FX architecture are presented, including the ECM performance model for A64FX and a discussion of performance characteristics of two important compute kernels (sparse matrix-vector multiplication and a domain wall kernel from quantum chromodynamics)."><b>The National High-Performance Computing Alliance – advancing the German HPC ecosystem</b></a>
</td>
</tr>
<tr>
<th>16:40~17:00</th>
<td><b>Kengo Nakajima</b> (The University of Tokyo)<br>
  <a href="Abstract/KengoNakajima.html" title="We have applied the prototype of h3-Open-BDEC to Seism3D/OpenSWPC-DAF (Data-Assimilation-Based Forecast), which was developed by ERI/U.Tokyo for integration of simulation and data assimilation. In this talk, we will describe the demonstration of real-time data assimilation of the developed code on the Oakbridge-CX system at the University of Tokyo, using measured data through JDXnet (Japan Data eXchange network) with 2,000+ high-sensitivity/broadband seismic observation stations in Japan."><b>Integration of 3D Earthquake Simulation & Real-Time Data Assimilation using h3-Open-BDEC</b></a>
</td>
</tr>
<tr>
<th>17:00~17:20</th>  
<td><b>Hiromichi Nagao</b> (Earthquake Research Institute, The University of Tokyo)<br>
 <a href="Abstract/HiromichiNagao.html" title="The four-dimensional variational method (4DVar) is one of the data assimilation techniques to integrate numerical simulations and observation data, which especially plays an important role in the cases of large-scale simulation models such as weather forecasting. The conventional 4DVar estimates only the optimum initial conditions and/or parameters for the simulation to fit the data, but never evaluates their uncertainties. We developed a new algorithm for 4DVar that enables us to quantify the uncertainties by the adoption of the second-order adjoint method, which computes the product of a Hessian matrix and an arbitrary given vector without knowing the Hessian matrix. We introduce the foundation of 4DVar and our algorithm for the uncertainty quantification, demonstrating the application results in the cases of the phase-field model that simulates the time-evolution of grain growth in media, and a simple model that simulates seismic wave propagation in the underground."><b>Optimization and Uncertainty Quantification based on the Four-Dimensional Variational Method</b></a>
</td>
</tr>
<tr>
<th>17:20~17:40</th>
<td><b>Hisashi Yashiro</b> (National Institute for Environmental Studies)<br>
 <a href="Abstract/HisashiYashiro.html" title="There are many historic HPC applications in various scientific and technological fields, and they often belong to different development communities or target issues at different detail levels. Integrating/unifying multiple legacy HPC applications can sometimes be very costly. Also, in the fusion of HPC and AI, it is important to utilize the simulation data of legacy HPC applications for machine learning and improve the performance of HPC applications by machine learning methods. To solve these problems, we are developing a library for "coupling." The coupling library h3-Open-UTIL/MP realizes coupled calculations by connecting HPC applications that have been individually used for simulation and analysis. Starting from combining closely related physics simulations, such as atmospheric and ocean simulations, we have extended h3-Open-UTIL/MP. One is ensemble coupling, and it is now possible to proceed with coupled simulation while both or one of the components performs ensemble calculations. The other is multi-approach coupling. We will introduce our study to gradually replace the physical model with the data-driven model, combining physics simulation written in Fortran and learning in a modern machine learning library written in Python online using h3-Open-UTIL/MP."><b>h3-Open-UTIL/MP: A General-purpose Coupling Library Bridging Legacy HPC Applications and the Future</b></a>
</td>
</tr>
<tr>
<th>17:40~18:00</th>  
<td><b>Hiroya Matsuba</b> (The University of Tokyo)<br>
 <a href="Abstract/HiroyaMatsuba.html" title=" Integration of simulation, data analytics, and machine learning requires communication between different types of parallel computers, such as ones with a massive number of nodes and ones with accelerators. Parallel computers of different types are usually installed as independent systems. MPI handles communication in each system, but it cannot do for communication across the systems. WaitIO is a new communication library that provides a communication infrastructure for applications that utilize multiple parallel computers. While providing similar APIs with MPI, it provides communication functionalities between parallel computers where TCP/IP or shared file systems are only the way of communication. This talk introduces the basic design of WaitIO and reports its performance and scalabilities."><b> Generic TCP/IP and File-based Communication Library for Heterogeneous Parallel Computer</b></a>
</td>
</tr>
<tr>
<th>18:00~18:10</th>  
<td><b>Closing</b>
</td>
</tr>

</table>



</section>


</div>
<!--/contents-->

<footer>
<small>
<strong>Contact e-mail:</strong>h3-open-bdec-all□googlegroups.com<br>
<strong>Main sponser:</strong>Japan Society for the Promotion of Science (JSPS)<br>
<strong>Research Theme:</strong><a href="https://h3-open-bdec.cc.u-tokyo.ac.jp/">
h3-Open-BDEC:An Innovative Method for Integration of Simulation /Data/Learning in the Exascale/Post-Moore Era</a><br>
<img src="./images/logo_h3-Open-BDEC.jpg" width="300px" alt="h3-Open-BDEC logo"> <br>
(C) Workshop organized committee </small>
<!-- Copyright&copy; <a href="index.html">SAMPLE SITE</a> All Rights Reserved.</small> -->
<span class="pr">《<a href="https://template-party.com/" target="_blank">Web Design:Template-Party</a>》</span>
</footer>

</div>
<!--/container-->

</body>
</html>
